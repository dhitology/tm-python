{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "001_Text_Preprocessing_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhitology/tm-python/blob/master/001_Text_Cleaning_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR34l7cfgI0H",
        "colab_type": "text"
      },
      "source": [
        "*Muhammad Apriandito Arya Saputra*\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iipKPhvLB3Pr",
        "colab_type": "text"
      },
      "source": [
        "# **Text Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWKfwoFDSCHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Data\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/dhitology/temporary/master/from_indonesia.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKWi-qGlbMue",
        "colab_type": "text"
      },
      "source": [
        "## **Basic Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni1l0qW3SIRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Text Cleaning Function using Regex\n",
        "import re\n",
        "\n",
        "def  clean_text(df, text_field, new_text_field_name):\n",
        "    df[new_text_field_name] = df[text_field].str.lower()\n",
        "    df[new_text_field_name] = df[new_text_field_name].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))  \n",
        "    # remove numbers\n",
        "    df[new_text_field_name] = df[new_text_field_name].apply(lambda elem: re.sub(r\"\\d+\", \"\", elem))\n",
        "    return df\n",
        "\n",
        "# Apply to the data\n",
        "df_clean = clean_text(df, 'text', 'text_clean')\n",
        "df_clean.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4ScPxspSWgC",
        "colab_type": "text"
      },
      "source": [
        "## **Stopword**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVbjBp1W6qvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Stopword\n",
        "import nltk.corpus\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Apply Stopword to the dataframe\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "df_clean['stopword'] = df_clean['text_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "df_clean.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijBoTJcKSojo",
        "colab_type": "text"
      },
      "source": [
        "## **Tokenize**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrkxYqIL7Ebl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inport Punkt\n",
        "import nltk \n",
        "nltk.download('punkt')\n",
        "\n",
        "# Tokenize\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "df_clean['tokenize'] = df_clean['text_clean'].apply(lambda x: word_tokenize(x))\n",
        "df_clean.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3v5Y_CVS9VK",
        "colab_type": "text"
      },
      "source": [
        "## **Stemming**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Otx2dKbB7OPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Stemmer\n",
        "from nltk.stem import PorterStemmer \n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Create Stemmer Function\n",
        "def word_stemmer(text):\n",
        "    stem_text = [PorterStemmer().stem(i) for i in text]\n",
        "    return stem_text\n",
        "\n",
        "# Apply to the dataframe\n",
        "df_clean['stemming'] = df_clean['tokenize'].apply(lambda x: word_stemmer(x))\n",
        "data_clean.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upSjs2JXTOHh",
        "colab_type": "text"
      },
      "source": [
        "## **Lemmatization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rGYrO_l7aAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Wordnet Library\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Create Lematization Funtion\n",
        "def word_lemmatizer(text):\n",
        "    lem_text = [WordNetLemmatizer().lemmatize(i, pos='v') for i in text]\n",
        "    return lem_text\n",
        "\n",
        "# Apply to a dataframe\n",
        "df_clean['lemmatization'] = df_clean['tokenize'].apply(lambda x: word_lemmatizer(x))\n",
        "df_clean.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnwAgH5WVrNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Do some fix\n",
        "df_join = df_clean['lemmatization'].str.join(\",\") \n",
        "df_final = df_join.str.replace(',', ' ', regex=False)\n",
        "df_final = pd.DataFrame(df_final)\n",
        "df_final.rename(columns={'lemmatization': 'text'}, inplace = True)\n",
        "df_final.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnLfiZyyZQGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save as CSV\n",
        "df_final.to_csv('clean.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}